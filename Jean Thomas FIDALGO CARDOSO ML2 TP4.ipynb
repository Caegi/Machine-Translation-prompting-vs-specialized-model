{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2bb23dc-b0d8-4f7e-8901-2d1e91916c09",
   "metadata": {},
   "source": [
    "# Which translation model is used when using an HuggingFace translation pipeline ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60416b-a1ba-484c-94e0-b09164317759",
   "metadata": {},
   "source": [
    "For default, but from the transformer translation documentation in hugging face, I found that the Text-To-Text Transfer Transformer (T5) small from Google is used, especially the my_awesome_opus_books_model model - a fine-tuned version of t5-small on the opus_books dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b17ae-f05e-4ece-b4fa-966efbf6cd6c",
   "metadata": {},
   "source": [
    "# What is the BLEU score achieved on the challenge set by an LLM ? by the translation pipeline ? How long does it take to translation the test set with a LLM ? With a specific model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6c17e-cdfe-4430-ac70-5196aadfd4fa",
   "metadata": {},
   "source": [
    "<i> The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm ...<i> https://til.hashnode.dev/running-an-llm-locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7f0fe8-7616-468c-9afa-2e5d69588e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from functools import partial\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ea4e0d-97dd-4aa8-bbcb-f574c916d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_minor</th>\n",
       "      <th>reference</th>\n",
       "      <th>category_major</th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>systems</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S-V agreement, across distractors</td>\n",
       "      <td>Les appels répétés de sa mère auraient dû nous...</td>\n",
       "      <td>Morpho-Syntactic</td>\n",
       "      <td>Is subject-verb agrement correct? (Possible in...</td>\n",
       "      <td>The repeated calls from his mother should have...</td>\n",
       "      <td>[{'output': 'Les appels répétés de sa mère aur...</td>\n",
       "      <td>S1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S-V agreement, across distractors</td>\n",
       "      <td>Le bruit soudain dans les chambres supérieures...</td>\n",
       "      <td>Morpho-Syntactic</td>\n",
       "      <td>Is subject-verb agrement correct? (Possible in...</td>\n",
       "      <td>The sudden noise in the upper rooms should hav...</td>\n",
       "      <td>[{'output': 'Le bruit soudain dans les chambre...</td>\n",
       "      <td>S1b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S-V agreement, across distractors</td>\n",
       "      <td>Leurs échecs répétés à signaler le problème au...</td>\n",
       "      <td>Morpho-Syntactic</td>\n",
       "      <td>Is subject-verb agrement correct? (Possible in...</td>\n",
       "      <td>Their repeated failures to report the problem ...</td>\n",
       "      <td>[{'output': 'Leur échec répété à signaler le p...</td>\n",
       "      <td>S1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S-V agreement, through control verbs</td>\n",
       "      <td>Elle a demandé à son frère de ne pas se montre...</td>\n",
       "      <td>Morpho-Syntactic</td>\n",
       "      <td>Does the flagged adjective agree correctly wit...</td>\n",
       "      <td>She asked her brother not to be arrogant.</td>\n",
       "      <td>[{'output': 'Elle a demandé à son frère de ne ...</td>\n",
       "      <td>S2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S-V agreement, through control verbs</td>\n",
       "      <td>Elle a promis à son frère de ne pas être arrog...</td>\n",
       "      <td>Morpho-Syntactic</td>\n",
       "      <td>Does the flagged adjective agree correctly wit...</td>\n",
       "      <td>She promised her brother not to be arrogant.</td>\n",
       "      <td>[{'output': 'Elle a promis à son frère de ne p...</td>\n",
       "      <td>S2b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category_minor  \\\n",
       "0     S-V agreement, across distractors   \n",
       "1     S-V agreement, across distractors   \n",
       "2     S-V agreement, across distractors   \n",
       "3  S-V agreement, through control verbs   \n",
       "4  S-V agreement, through control verbs   \n",
       "\n",
       "                                           reference    category_major  \\\n",
       "0  Les appels répétés de sa mère auraient dû nous...  Morpho-Syntactic   \n",
       "1  Le bruit soudain dans les chambres supérieures...  Morpho-Syntactic   \n",
       "2  Leurs échecs répétés à signaler le problème au...  Morpho-Syntactic   \n",
       "3  Elle a demandé à son frère de ne pas se montre...  Morpho-Syntactic   \n",
       "4  Elle a promis à son frère de ne pas être arrog...  Morpho-Syntactic   \n",
       "\n",
       "                                            question  \\\n",
       "0  Is subject-verb agrement correct? (Possible in...   \n",
       "1  Is subject-verb agrement correct? (Possible in...   \n",
       "2  Is subject-verb agrement correct? (Possible in...   \n",
       "3  Does the flagged adjective agree correctly wit...   \n",
       "4  Does the flagged adjective agree correctly wit...   \n",
       "\n",
       "                                              source  \\\n",
       "0  The repeated calls from his mother should have...   \n",
       "1  The sudden noise in the upper rooms should hav...   \n",
       "2  Their repeated failures to report the problem ...   \n",
       "3          She asked her brother not to be arrogant.   \n",
       "4       She promised her brother not to be arrogant.   \n",
       "\n",
       "                                             systems   id  \n",
       "0  [{'output': 'Les appels répétés de sa mère aur...  S1a  \n",
       "1  [{'output': 'Le bruit soudain dans les chambre...  S1b  \n",
       "2  [{'output': 'Leur échec répété à signaler le p...  S1c  \n",
       "3  [{'output': 'Elle a demandé à son frère de ne ...  S2a  \n",
       "4  [{'output': 'Elle a promis à son frère de ne p...  S2b  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get challenge set\n",
    "df = pd.read_json( os.path.join(*[\"/home\", \"caegi\", \"Documents\", \"M1\", \"ML\", \n",
    "                        \"ML2\", \"TP4\", \"D17-1263.Attachment\", \"Challenge_set-v2hA.json\"]), lines=True)\n",
    "\n",
    "# I am removing brackets to limit the prompting and translation models' tomfoolery (it makes the BLEU score better)\n",
    "def remove_brackets(s):\n",
    "    return re.sub(\"\\[|\\]\", '', s)\n",
    "\n",
    "df[\"reference\"] = df[\"reference\"].apply(remove_brackets)\n",
    "df[\"source\"] = df[\"source\"].apply(remove_brackets)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a8844-6490-4cb8-b2cd-82eccd86e959",
   "metadata": {},
   "source": [
    "## LLM (text generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bc8642-7689-4ced-9a98-c6954f29848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f87ab60a77e4badb50a50a73572e608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f33712b977e4ded84646c299718bfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/yashar1908/Text-translation-using-Mistral-7B/blob/main/LLM_for_Translation.ipynb\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "model_type = \"mistral\", gpu_layers = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a4ac54-7bd4-4366-a531-486fc2c19ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_llm(s):\n",
    "    prompt = f'Translate this Text from French to English:{s} Translation:'\n",
    "    return llm(prompt, max_new_tokens=100, temperature=0.9, top_k=55, top_p=0.93, repetition_penalty=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed89abd3-0969-4326-8134-d4ef3ecf4eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 24s, sys: 27 s, total: 7min 51s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%time predictions_llm = df[\"reference\"].apply(get_translation_llm).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fff8d-dc76-4bb2-aa9b-b69fa30b7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = df[\"source\"].to_list()\n",
    "\n",
    "# see some results\n",
    "for i in range(3):\n",
    "    print(\"\\n\", df[\"reference\"][i])\n",
    "    print(\"Gold Translation is: \", references[i])\n",
    "    print(\"Prompting Translation is: \", predictions_llm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552a685a-6757-4422-97b2-5b67a9f56cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text generation bleu score: 50.25696048117239\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "print(\"text generation bleu score:\", sacrebleu.compute(predictions=predictions_llm, references=references)[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63658bbf-06e1-4ec3-b27a-7424ec746cbf",
   "metadata": {},
   "source": [
    "## Translation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288f38a5-2581-4052-8314-3c4a877b501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "def get_translation_fr_en_model(s):\n",
    "    return translation_pipe(s, max_length=100)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7932a9d3-7790-42eb-aeae-0aabddf0d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 148 ms, total: 1min 18s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%time predictions_fr_en_model = df[\"reference\"].apply(get_translation_fr_en_model).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcbf8c23-46d6-40aa-97e5-9f2db5bbb5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr_en_model bleu score: 60.56494528173656\n"
     ]
    }
   ],
   "source": [
    "print(\"fr_en_model bleu score:\", sacrebleu.compute(predictions=predictions_fr_en_model, references=references)[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75c945-f179-4b1b-abc7-b0f9b6a2e853",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91e9f0-f405-4e08-81da-c6609793eb08",
   "metadata": {},
   "source": [
    "The blue score of the specialized machine translation model from french to english is better than the text generation model one, although the score of the LLM text generation model would be higher if I had more VRAM in my GPU to run a better model.\n",
    "\n",
    "The time difference to get the translations is significant. As you can see in the cell 5 and 10, the machine translation model is around 6 times faster than the text generation model. (1min 18s vs 7min 51s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
